{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time_Series_Analysis\n",
    "\n",
    "This is a Time Series practice problem on Analytics Vidhya.\n",
    "\n",
    "thao9611 [Here](https://github.com/thao9611/Time_Series_Analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from matplotlib.pylab import rcParams\n",
    "rcParams['figure.figsize'] = 15,8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train1 = pd.read_csv(\".\\\\data\\\\TSAnalysis-JetRail-Train.csv\")\n",
    "test= pd.read_csv(\".\\\\data\\\\TSAnalysis-JetRail-Test.csv\")\n",
    "#submit = pd.read_csv(\".\\\\data\\\\TSAnalysis-JetRail-Submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (18288, 3)\n",
      "Test shape: (5112, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Datetime</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25-08-2012 00:00</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>25-08-2012 01:00</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>25-08-2012 02:00</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>25-08-2012 03:00</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>25-08-2012 04:00</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID          Datetime  Count\n",
       "0   0  25-08-2012 00:00      8\n",
       "1   1  25-08-2012 01:00      2\n",
       "2   2  25-08-2012 02:00      6\n",
       "3   3  25-08-2012 03:00      2\n",
       "4   4  25-08-2012 04:00      2"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Train shape: \" + str(train1.shape))\n",
    "print(\"Test shape: \" + str(test.shape))\n",
    "train1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import floor\n",
    "#split the train data into training set and valid set\n",
    "train = train1.loc[:floor(2*train1.shape[0]/3)]\n",
    "valid = train1.loc[floor(2*train1.shape[0]/3):]\n",
    "train.set_index('Datetime', inplace = True)\n",
    "valid.set_index('Datetime', inplace = True)\n",
    "test.set_index('Datetime', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12193, 2)\n",
      "(6096, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>25-08-2012 00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25-08-2012 01:00</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25-08-2012 02:00</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25-08-2012 03:00</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25-08-2012 04:00</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  ID  Count\n",
       "Datetime                   \n",
       "25-08-2012 00:00   0      8\n",
       "25-08-2012 01:00   1      2\n",
       "25-08-2012 02:00   2      6\n",
       "25-08-2012 03:00   3      2\n",
       "25-08-2012 04:00   4      2"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print (train.shape)\n",
    "print (valid.shape)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2012-08-25 00:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2012-08-25 01:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2012-08-25 02:00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2012-08-25 03:00:00</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2012-08-25 04:00:00</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     ID  Count\n",
       "Datetime                      \n",
       "2012-08-25 00:00:00   0      8\n",
       "2012-08-25 01:00:00   1      2\n",
       "2012-08-25 02:00:00   2      6\n",
       "2012-08-25 03:00:00   3      2\n",
       "2012-08-25 04:00:00   4      2"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#parsing the datetime data \n",
    "dataparse = lambda dates: pd.datetime.strptime(dates, \"%d-%m-%Y %H:%M\")\n",
    "train.index = train.index.map(dataparse)\n",
    "valid.index = valid.index.map(dataparse)\n",
    "test.index = test.index.map(dataparse)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stationarity checking "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stationary: if its statistical properties such as mean, variance remain constant over time. Intuitively, if a TS has a particular behaviour over time , there is a high probability that it will follow the same in future. Criteria for stationary series:\n",
    "* Constant mean\n",
    "* Constant variable\n",
    "* Autocovariance that does not depend on time\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import adfuller\n",
    "def test_stationarity(timeseries):\n",
    "    \n",
    "    #Determing rolling statistics\n",
    "    rolmean = pd.rolling_mean(timeseries, window=24) # 24 hours on each day\n",
    "    rolstd = pd.rolling_std(timeseries, window=24)\n",
    "\n",
    "    #Plot rolling statistics:\n",
    "    orig = plt.plot(timeseries, color='blue',label='Original')\n",
    "    mean = plt.plot(rolmean, color='red', label='Rolling Mean')\n",
    "    std = plt.plot(rolstd, color='black', label = 'Rolling Std')\n",
    "    plt.legend(loc='best')\n",
    "    plt.title('Rolling Mean & Standard Deviation')\n",
    "    plt.show(block=False)\n",
    "    \n",
    "    #Perform Dickey-Fuller test:\n",
    "    print ('Results of Dickey-Fuller Test:')\n",
    "    dftest = adfuller(timeseries, autolag='AIC')\n",
    "    dfoutput = pd.Series(dftest[0:4], index=['Test Statistic','p-value','#Lags Used','Number of Observations Used'])\n",
    "    for key,value in dftest[4].items():\n",
    "        dfoutput['Critical Value (%s)'%key] = value\n",
    "    print (dfoutput)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'pandas' has no attribute 'rolling_mean'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-cb15cfda25f2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtest_stationarity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Count'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-7-e7fe2e6ec84d>\u001b[0m in \u001b[0;36mtest_stationarity\u001b[1;34m(timeseries)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;31m#Determing rolling statistics\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mrolmean\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrolling_mean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeseries\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwindow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m24\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# 24 hours on each day\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[0mrolstd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrolling_std\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeseries\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwindow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m24\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\pandas\\__init__.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(name)\u001b[0m\n\u001b[0;32m    212\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    213\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mPanel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 214\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"module 'pandas' has no attribute '{}'\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    215\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    216\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'pandas' has no attribute 'rolling_mean'"
     ]
    }
   ],
   "source": [
    "test_stationarity(train['Count'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evethough the Statistic Test show that the data is stationary ( Test Statistic < Critical Values), we still can see an increasing trend in the data. Therefore, we will try to make the data more stationary firstly. We need to remove two properties from the data: trend and seasonality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trend removing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trend: data varying mean over time. For example: the number of the value can increase or decrease over time.\n",
    "Estimating and Eliminating Trend techniques: \n",
    "Transformation: for example, for increasing trend, we can apply transformation which penalizes higher values more than smaller ones. For example: log, square roor,...\n",
    "Some ways to estimate and remove the trend:\n",
    "* Aggregation: taking average of time period lik monthly/weekly\n",
    "* Smoothing: taking rolling average\n",
    "* Polynomial fitting: fit a regression model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Smoothing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computing the rolling average of the data. Here we take the window size in 24 based on the fact that each day has 24 hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_log = np.log(train['Count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "moving_avg = pd.rolling_mean(train_log, 24)\n",
    "plt.plot(train_log)\n",
    "plt.plot(moving_avg, color = 'red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing the increasing trend \n",
    "train_log_moving_avg_diff = train_log - moving_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since we are taking the average of 24 values, rolling mean is not defined for the first 23 values. (NaN)\n",
    "train_log_moving_avg_diff.dropna(inplace = True)\n",
    "test_stationarity(train_log_moving_avg_diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Test Statistic values is way smaller than the critical value so we can be confident that the data is stationary now. A disadvantage of smoothing: the time period must strictly predicted. For example, in case of stock price, it may not be easy to come up with a time frame."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Exponentially weighted moving average"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EWMA is another popular technique where weights are assigned to all the previous values with a decay factor. Find details in here http://pandas.pydata.org/pandas-docs/stable/computation.html#exponentially-weighted-moment-functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expwighted_avg = pd.ewma(train_log, halflife=24)\n",
    "plt.plot(train_log)\n",
    "plt.plot(expwighted_avg, color='red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing the trend of increasing\n",
    "train_log_ewma_diff = train_log - expwighted_avg\n",
    "test_stationarity(train_log_ewma_diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We got almost similar result here. The trend is almost removed. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seasonality remove"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seasonality: variations at specific time-frames. E.g: people have tendency to buy jacket in winters\n",
    "To remove the seasonality, we have two techniques:\n",
    "   * Differencing: taking the difference with a particular time lag\n",
    "   * Decomposition: modeling both trend and seasonality and removing them from the model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Differencing \n",
    "Usually, non-stationary series can be corrected by just differencing.The idea behind differencing is that, if the original data series does not have constant properties over time, then the change from one period to another might."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_log_diff = train_log - train_log.shift()\n",
    "test_stationarity(train_log_diff.dropna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_log_diff.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decomposition \n",
    "In decomposition, trend and seasonality are treated separatedly. Let's recall the definitions: \n",
    "* Trend: The increasing or decreasing value in the series.\n",
    "* Seasonality: The repeating short-term cycle in the series.\n",
    "* Residual: The random variation in the series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "decomposition = seasonal_decompose(pd.DataFrame(train_log).Count.values, freq = 24)\n",
    "\n",
    "trend = decomposition.trend\n",
    "seasonal = decomposition.seasonal\n",
    "residual = decomposition.resid\n",
    "\n",
    "plt.subplot(411)\n",
    "plt.plot(train_log, label='Original')\n",
    "plt.legend(loc='best')\n",
    "plt.subplot(412)\n",
    "plt.plot(trend, label='Trend')\n",
    "plt.legend(loc='best')\n",
    "plt.subplot(413)\n",
    "plt.plot(seasonal,label='Seasonality')\n",
    "plt.legend(loc='best')\n",
    "plt.subplot(414)\n",
    "plt.plot(residual, label='Residuals')\n",
    "plt.legend(loc='best')\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A closer look at the seasonality \n",
    "plt.plot(seasonal[:200],label='Sub-Seasonality')\n",
    "plt.legend(loc='best')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see that the trend, seasonality are separated out from data and we can model the residuals. The trend line show a gradual increasing trend, while the seasonality show a constant trend in counter. \n",
    "Lets check stationarity of residuals, which should have no pattern and normally distributed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_log_decompose = pd.DataFrame(residual)\n",
    "train_log_decompose['date'] = train_log.index\n",
    "train_log_decompose.set_index('date', inplace = True)\n",
    "train_log_decompose.dropna(inplace=True)\n",
    "test_stationarity(train_log_decompose[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forecast a Time Series\n",
    "To fit and predict a time series, we use ARIMA, which stands for auto-regressive integrated moving average and is specified by these three order parameters: (p, d, q). \n",
    "* Auto regressive (AR(p)): referring to the use of past values in the regression equation for the series Y. p specifies the number of lags used in the model. For instance if p is 2, the predictors for x(t) will be x(t-1)x(t-2). AR(2) or, equivalently, ARIMA(2,0,0), is represented as\n",
    "\n",
    "$$Y_t = c + \\phi_1y_{t-1} + \\phi_2 y_{t-2}+ e_t$$\n",
    "where φ1, φ2 are parameters for the model.\n",
    "\n",
    "* Moving average (MA(q)): representing the error of the model as a combination of previous error terms et. q determines the number of terms to include in the model. For instance if q is 5, the predictors for x(t) will be e(t-1)….e(t-5) where e(i) is the difference between the moving average at ith instant and actual value.\n",
    "\n",
    "$$Y_t = c + \\theta_1 e_{t-1} + \\theta_2 e_{t-2} +...+ \\theta_q e_{t-q}+ e_t$$\n",
    "\n",
    "* d represents the degree of differencing in the integrated (I(d)) component. For example, when d = 1 and d = 2:\n",
    "\n",
    "$$Y_{d_t} = Y_t - Y_{t-1}$$\n",
    "\n",
    "$$Y_{d2_t} = Y_{d_t} - Y_{d_t-1} = (Y_t - Y_{t-1}) - (Y_{t-1} - Y_{t-2})$$\n",
    " \n",
    "\n",
    "\n",
    "Differencing, autoregressive, and moving average components make up a non-seasonal ARIMA model which can be written as a linear equation:\n",
    "\n",
    "$$ Y_t = c + \\phi_1y_d{_{t-1}} +...+ \\phi_p y_d{_{t-p}}+\\theta_1 e_{t-1} +... + \\theta_q e_{t-q} + e_t$$\n",
    "\n",
    "where yd is Y differenced d times and c is a constant.\n",
    "\n",
    "Note that the model above assumes non-seasonal series, which means you might need to de-seasonalize the series before modeling. ARIMA methodology does have its limitations. These models directly rely on past values, and therefore work best on long and stable series. Also note that ARIMA simply approximates historical patterns and therefore does not aim to explain the structure of the underlying data mechanism."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An importance concern here is how to determine the value of ‘p’ and ‘q’. We use two plots to determine these numbers. Lets discuss them first.\n",
    "\n",
    "* Autocorrelation Function (ACF): It is a measure of the correlation between the the TS with a lagged version of itself. For instance at lag 5, ACF would compare series at time instant ‘t1’…’t2’ with series at instant ‘t1-5’…’t2-5’ (t1-5 and t2 being end points).\n",
    "\n",
    "* Partial Autocorrelation Function (PACF): This measures the correlation between the TS with a lagged version of itself but after eliminating the variations already explained by the intervening comparisons. Eg at lag 5, it will check the correlation but remove the effects already explained by lags 1 to 4.\n",
    "\n",
    "https://people.duke.edu/~rnau/411arim3.htm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ACF and PACF plots:\n",
    "from statsmodels.tsa.stattools import acf, pacf\n",
    "lag_acf = acf(train_log_diff.dropna(), nlags=25)\n",
    "lag_pacf = pacf(train_log_diff.dropna(), nlags=25, method='ols')\n",
    "#Plot ACF: \n",
    "plt.subplot(121) \n",
    "plt.plot(lag_acf)\n",
    "plt.axhline(y=0,linestyle='--',color='gray')\n",
    "plt.axhline(y=-1.96/np.sqrt(len(train_log_diff.dropna())),linestyle='--',color='gray')\n",
    "plt.axhline(y=1.96/np.sqrt(len(train_log_diff.dropna())),linestyle='--',color='gray')\n",
    "plt.title('Autocorrelation Function')\n",
    "#Plot PACF:\n",
    "plt.subplot(122)\n",
    "plt.plot(lag_pacf)\n",
    "plt.axhline(y=0,linestyle='--',color='gray')\n",
    "plt.axhline(y=-1.96/np.sqrt(len(train_log_diff.dropna())),linestyle='--',color='gray')\n",
    "plt.axhline(y=1.96/np.sqrt(len(train_log_diff.dropna())),linestyle='--',color='gray')\n",
    "plt.title('Partial Autocorrelation Function')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_log_diff.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this plot, the two dotted lines on either sides of 0 are the confidence interevals. These can be used to determine the ‘p’ and ‘q’ values as:\n",
    "\n",
    "* p – The lag value where the PACF chart crosses the upper confidence interval for the first time. If you notice closely, in this case p=1. And we also can see there is a spike at p = 1\n",
    "\n",
    "* q – The lag value where the ACF chart crosses the upper confidence interval for the first time. If you notice closely, in this case q=1. And we can also see there is a spike at q =1 ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.arima_model import ARIMA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The p,d,q values can be specified using the order argument of ARIMA which take a tuple (p,d,q). Let model the 3 cases: AR model, MA model and the combined model. Here, RSS stands for residual sum of squares.  A small RSS indicates a tight fit of the model to the data. It is used as an optimality criterion in parameter selection and model selection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AR Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ARIMA(train_log, order=(1, 1, 0))  \n",
    "results_AR = model.fit(disp=-1)  \n",
    "plt.plot(train_log_diff.dropna())\n",
    "plt.plot(results_AR.fittedvalues, color='red')\n",
    "plt.title('RSS: %.4f'% sum((results_AR.fittedvalues-train_log_diff)**2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MA model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ARIMA(train_log, order=(0, 1, 1))  \n",
    "results_ARIMA = model.fit(disp=-1)  \n",
    "plt.plot(train_log_diff.dropna())\n",
    "plt.plot(results_ARIMA.fittedvalues, color='red')\n",
    "plt.title('RSS: %.4f'% sum((results_ARIMA.fittedvalues-train_log_diff)**2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combined model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ARIMA(train_log, order=(1, 1, 1))  \n",
    "results_MA = model.fit(disp=-1)  \n",
    "plt.plot(train_log_diff.dropna())\n",
    "plt.plot(results_MA.fittedvalues, color='red')\n",
    "plt.title('RSS: %.4f'% sum((results_MA.fittedvalues-train_log_diff)**2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Taking it back to the original scale\n",
    "Lets scale it back to the original values and see how well it performs there. First step would be to store the predicted results as a separate series and observe it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bring the differencing back to the original scale\n",
    "def check_prediction_diff(predict_diff, given_set):\n",
    "    predict_diff= predict_diff.cumsum().shift().fillna(0)\n",
    "    predict_base = pd.Series(np.ones(given_set.shape[0]) * np.log(given_set['Count'])[0], index = given_set.index)\n",
    "    predict_log = predict_base.add(predict_diff,fill_value=0)\n",
    "    predict = np.exp(predict_log)\n",
    "    \n",
    "    plt.plot(given_set['Count'], label = \"Given set\")\n",
    "    plt.plot(predict, color = 'red', label = \"Predict\")\n",
    "    plt.legend(loc= 'best')\n",
    "    plt.title('RMSE: %.4f'% (np.sqrt(np.dot(predict, given_set['Count']))/given_set.shape[0]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_prediction_log(predict_log, given_set):\n",
    "    predict = np.exp(predict_log)\n",
    "    \n",
    "    plt.plot(given_set['Count'], label = \"Given set\")\n",
    "    plt.plot(predict, color = 'red', label = \"Predict\")\n",
    "    plt.legend(loc= 'best')\n",
    "    plt.title('RMSE: %.4f'% (np.sqrt(np.dot(predict, given_set['Count']))/given_set.shape[0]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tried on MA model \n",
    "model = ARIMA(train_log.dropna(), order=(0, 1, 1))  \n",
    "results_ARIMA = model.fit(disp=-1)  \n",
    "predictions_ARIMA_diff = pd.Series(results_ARIMA.fittedvalues, copy=True)\n",
    "print (predictions_ARIMA_diff.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_prediction(predictions_ARIMA_diff, train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict on the valid set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = train.shape[0]\n",
    "end = start + valid.shape[0]\n",
    "valid_predict_diff = results_ARIMA.predict(start = start-1, end = end-2, typ = 'levels')\n",
    "print (valid_predict_diff.head())\n",
    "print (valid_predict_diff.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_prediction_log(valid_predict_diff, valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
