{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to Choose a Feature Selection Method For Machine Learning\n",
    "by Jason Brownlee on June 30, 2020. [Here](https://machinelearningmastery.com/feature-selection-with-real-and-categorical-data/) in [Data Preparation](https://machinelearningmastery.com/category/data-preparation/)\n",
    "\n",
    "Feature selection is the process of `reducing the number of input variables` when developing a predictive model.\n",
    "\n",
    "It is desirable to reduce the number of input variables to both `reduce the computational cost` of modeling and, in some cases, to `improve the performance` of the model.\n",
    "\n",
    "In this post, you will discover how to choose statistical measures for filter-based feature selection with `numerical` and `categorical` data.\n",
    "\n",
    "After reading this post, you will know:\n",
    "\n",
    "- There are two main types of feature selection techniques: `supervised` and `unsupervised`, and supervised methods may be divided into *wrapper*, *filter* and *intrinsic*.\n",
    "- Filter-based feature selection methods use statistical measures to score the correlation or dependence between input variables that can be filtered to choose the most relevant features.\n",
    "- Statistical measures for feature *`selection must be carefully chosen based on the data type of the input variable and the output or response variable`*.\n",
    "\n",
    "## Overview\n",
    "This tutorial is divided into 4 parts; they are:\n",
    "\n",
    "1. Feature Selection Methods\n",
    "2. Statistics for Filter Feature Selection Methods\n",
    "    1. Numerical Input, Numerical Output\n",
    "    2. Numerical Input, Categorical Output\n",
    "    3. Categorical Input, Numerical Output\n",
    "    4. Categorical Input, Categorical Output\n",
    "3. Tips and Tricks for Feature Selection\n",
    "    1. Correlation Statistics\n",
    "    2. Selection Method\n",
    "    3. Transform Variables\n",
    "    4. What Is the Best Method?\n",
    "4. Worked Examples\n",
    "    1. Regression Feature Selection\n",
    "    2. Classification Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Feature Selection Methods\n",
    "Feature selection methods are intended to reduce the number of input variables to those that are believed to be most useful to a model in order to predict the target variable.\n",
    "\n",
    "Many models, especially those based on `regression slopes` and `intercepts`, will estimate parameters for every term in the model. Because of this, the presence of non-informative -*that are not relevant to the target variable*- variables can add uncertainty to the predictions and reduce the overall effectiveness of the model.\n",
    "\n",
    "We can summarize feature selection as follows.\n",
    "\n",
    "- Feature Selection: Select a subset of input features from the dataset.\n",
    "    - Unsupervised: Do not use the target variable (e.g. remove redundant variables).\n",
    "        - Correlation\n",
    "    - Supervised: Use the target variable (e.g. remove irrelevant variables).\n",
    "        - Wrapper: Search for well-performing subsets of features (maximizes model performance).\n",
    "            - RFE\n",
    "        - Filter: Select subsets of features based on their relationship with the target.\n",
    "            - Statistical Methods\n",
    "            - Feature Importance Methods\n",
    "        - Intrinsic: Algorithms that perform automatic feature selection during training (intrinsically conduct feature selection).\n",
    "            - Decision Trees\n",
    "            - Rule-based models, MARS, randon forest, and the lasso, for example. \n",
    "- Dimensionality Reduction: Project input data into a lower-dimensional feature space (create a projection of the data resulting in entirely new input features)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 2. Statistics for Filter Feature Selection Methods\n",
    "### 1. Numerical Input, Numerical Output\n",
    "### 2. Numerical Input, Categorical Output\n",
    "### 3. Categorical Input, Numerical Output\n",
    "### 4. Categorical Input, Categorical Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 3. Tips and Tricks for Feature Selection\n",
    "### 1. Correlation Statistics\n",
    "### 2. Selection Method\n",
    "### 3. Transform Variables\n",
    "### 4. What Is the Best Method?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 4. Worked Examples\n",
    "### 1. Regression Feature Selection\n",
    "### 2. Classification Feature Selection"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}