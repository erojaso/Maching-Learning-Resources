{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Discriminant Analysis for Machine Learning\n",
    "\n",
    "by Jason Brownlee on February 4, 2020.[Here](https://machinelearningmastery.com/linear-discriminant-analysis-for-machine-learning/) in [Machine Learning Algorithms](https://machinelearningmastery.com/category/machine-learning-algorithms/)\n",
    "\n",
    "Logistic regression is a classification algorithm traditionally limited to only two-class classification problems.\n",
    "\n",
    "If you have more than two classes then Linear Discriminant Analysis is the preferred linear classification technique.\n",
    "\n",
    "In this post you will discover the Linear Discriminant Analysis (LDA) algorithm for classification predictive modeling problems.\n",
    "\n",
    "- The limitations of logistic regression and the need for Linear Discriminant Analysis.\n",
    "- The representation of the model that is learned from data and can be saved to file.\n",
    "- How the model is estimated from your data.\n",
    "- How to make predictions from a learned LDA model.\n",
    "- How to prepare your data to get the most from the LDA model.\n",
    "\n",
    "## Overview\n",
    "1. Limitations of Logistic Regression\n",
    "2. Representation of LDA Models\n",
    "3. Learning LDA Models\n",
    "4. Making Predictions with LDA\n",
    "5. How to Prepare Data for LDA\n",
    "6. Extensions to LDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Limitations of Logistic Regression\n",
    "Logistic regression is a simple and powerful linear classification algorithm. It also has limitations that suggest at the need for alternate linear classification algorithms.\n",
    "- __Two or more Class__.\n",
    "- __Unstable With Well Separated Classes__. \n",
    "- __Unstable With Few Examples__. \n",
    "\n",
    "Linear Discriminant Analysis does address each of these points and is the go-to linear method for multi-class classification problems. Even with binary-classification problems, it is a good idea to try both logistic regression and linear discriminant analysis.\n",
    "\n",
    "## 2. Representation of LDA Models\n",
    "It consists of statistical properties of your data, calculated for each class. For a __single input__ variable (x) this is the `mean` and the `variance` of the variable for each class. For __multiple variables__, this is the same properties `calculated over the multivariate Gaussian, namely the means and the covariance matrix`.\n",
    "\n",
    "These statistical properties are estimated from your data and plug into the LDA equation to make predictions.\n",
    "\n",
    "## 3. Learning LDA Models\n",
    "LDA makes some simplifying __assumptions__ about your data:\n",
    "\n",
    "- That your __data is Gaussian__, that each variable is is shaped like a bell curve when plotted.\n",
    "- That each attribute __has the same variance__, that values of each variable vary around the mean by the same amount on average.\n",
    "\n",
    "\n",
    "## 4. Making Predictions with LDA\n",
    "LDA makes predictions by estimating the probability that a new set of inputs belongs to each class. The class that gets the highest probability is the output class and a prediction is made.\n",
    "\n",
    "## 5. How to Prepare Data for LDA\n",
    "This section lists some suggestions you may consider when preparing your data for use with LDA.\n",
    "\n",
    "- __Classification Problems__. This might go without saying, but LDA is intended for classification problems `where the output variable is categorical`. LDA supports both `binary` and `multi-class classification`.\n",
    "- __Gaussian Distribution__. The standard implementation of the model `assumes a Gaussian distribution` of the input variables. Consider reviewing the univariate distributions of each attribute and using transforms to make them more Gaussian-looking (e.g. __log__ and __root__ for `exponential distributions` and __Box-Cox__ for `skewed distributions`).\n",
    "- __Remove Outliers__. Consider removing outliers from your data. These can skew the basic statistics used to separate classes in LDA such the mean and the standard deviation.\n",
    "- __Same Variance__. LDA assumes that each input variable has the same variance. It is almost always a good idea to __standardize__ your data before using LDA so that it has a mean of 0 and a standard deviation of 1.\n",
    "\n",
    "## 6. Extensions to LDA\n",
    "Linear Discriminant Analysis is a simple and effective method for classification. Because it is simple and so well understood, there are many extensions and variations to the method. Some popular extensions include:\n",
    "\n",
    "- __Quadratic Discriminant Analysis (QDA)__: Each class uses its own estimate of variance (or covariance when there are multiple input variables).\n",
    "- __Flexible Discriminant Analysis (FDA)__: Where non-linear combinations of inputs is used such as splines.\n",
    "- __Regularized Discriminant Analysis (RDA)__: Introduces regularization into the estimate of the variance (actually covariance), moderating the influence of different variables on LDA.\n",
    "\n",
    "The original development was called the __Linear Discriminant__ or __Fisherâ€™s Discriminant Analysis__. The multi-class version was referred to __Multiple Discriminant Analysis__."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
